{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzMqROcf5ofz",
        "outputId": "35e4772e-d21f-42ae-aafc-870505317314"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: kaggle in /home/moddo/.local/lib/python3.10/site-packages (1.7.4.2)\n",
            "Requirement already satisfied: bleach in /home/moddo/.local/lib/python3.10/site-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /home/moddo/.local/lib/python3.10/site-packages (from kaggle) (2024.6.2)\n",
            "Requirement already satisfied: charset-normalizer in /home/moddo/.local/lib/python3.10/site-packages (from kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna in /home/moddo/.local/lib/python3.10/site-packages (from kaggle) (3.7)\n",
            "Requirement already satisfied: protobuf in /home/moddo/.local/lib/python3.10/site-packages (from kaggle) (4.25.3)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /home/moddo/.local/lib/python3.10/site-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /home/moddo/.local/lib/python3.10/site-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /home/moddo/.local/lib/python3.10/site-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /home/moddo/.local/lib/python3.10/site-packages (from kaggle) (69.0.3)\n",
            "Requirement already satisfied: six>=1.10 in /home/moddo/.local/lib/python3.10/site-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: text-unidecode in /home/moddo/.local/lib/python3.10/site-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /home/moddo/.local/lib/python3.10/site-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /home/moddo/.local/lib/python3.10/site-packages (from kaggle) (1.26.19)\n",
            "Requirement already satisfied: webencodings in /home/moddo/.local/lib/python3.10/site-packages (from kaggle) (0.5.1)\n",
            "\u001b[33mWARNING: Error parsing dependencies of distro-info: Invalid version: '1.1build1'\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in /home/moddo/.local/lib/python3.10/site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /home/moddo/.local/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/moddo/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/moddo/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/moddo/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/moddo/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "\u001b[33mWARNING: Error parsing dependencies of distro-info: Invalid version: '1.1build1'\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy in /home/moddo/.local/lib/python3.10/site-packages (1.26.4)\n",
            "\u001b[33mWARNING: Error parsing dependencies of distro-info: Invalid version: '1.1build1'\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
            "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torch in /home/moddo/.local/lib/python3.10/site-packages (2.6.0)\n",
            "Requirement already satisfied: filelock in /home/moddo/.local/lib/python3.10/site-packages (from torch) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /home/moddo/.local/lib/python3.10/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /home/moddo/.local/lib/python3.10/site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /home/moddo/.local/lib/python3.10/site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /home/moddo/.local/lib/python3.10/site-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/moddo/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/moddo/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/moddo/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/moddo/.local/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/moddo/.local/lib/python3.10/site-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/moddo/.local/lib/python3.10/site-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/moddo/.local/lib/python3.10/site-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/moddo/.local/lib/python3.10/site-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/moddo/.local/lib/python3.10/site-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/moddo/.local/lib/python3.10/site-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/moddo/.local/lib/python3.10/site-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/moddo/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/moddo/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /home/moddo/.local/lib/python3.10/site-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /home/moddo/.local/lib/python3.10/site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/moddo/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/moddo/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
            "\u001b[33mWARNING: Error parsing dependencies of distro-info: Invalid version: '1.1build1'\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torchvision in /home/moddo/.local/lib/python3.10/site-packages (0.21.0)\n",
            "Requirement already satisfied: numpy in /home/moddo/.local/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.6.0 in /home/moddo/.local/lib/python3.10/site-packages (from torchvision) (2.6.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/moddo/.local/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
            "Requirement already satisfied: filelock in /home/moddo/.local/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /home/moddo/.local/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /home/moddo/.local/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /home/moddo/.local/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /home/moddo/.local/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/moddo/.local/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/moddo/.local/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/moddo/.local/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/moddo/.local/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/moddo/.local/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/moddo/.local/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/moddo/.local/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/moddo/.local/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/moddo/.local/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/moddo/.local/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/moddo/.local/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/moddo/.local/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/moddo/.local/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /home/moddo/.local/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /home/moddo/.local/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/moddo/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/moddo/.local/lib/python3.10/site-packages (from jinja2->torch==2.6.0->torchvision) (2.1.5)\n",
            "\u001b[33mWARNING: Error parsing dependencies of distro-info: Invalid version: '1.1build1'\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torch.optim in /home/moddo/.local/lib/python3.10/site-packages (0.0.4)\n",
            "Requirement already satisfied: deap>=1.3.1 in /home/moddo/.local/lib/python3.10/site-packages (from torch.optim) (1.4.2)\n",
            "Requirement already satisfied: pytorch-ignite>=0.4.8 in /home/moddo/.local/lib/python3.10/site-packages (from torch.optim) (0.5.1)\n",
            "Requirement already satisfied: thop>=0.0.31 in /home/moddo/.local/lib/python3.10/site-packages (from torch.optim) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.10.0 in /home/moddo/.local/lib/python3.10/site-packages (from torch.optim) (2.6.0)\n",
            "Requirement already satisfied: torch-pruning>=0.2.7 in /home/moddo/.local/lib/python3.10/site-packages (from torch.optim) (1.5.1)\n",
            "Requirement already satisfied: torchvision>=0.11.1 in /home/moddo/.local/lib/python3.10/site-packages (from torch.optim) (0.21.0)\n",
            "Requirement already satisfied: numpy in /home/moddo/.local/lib/python3.10/site-packages (from deap>=1.3.1->torch.optim) (1.26.4)\n",
            "Requirement already satisfied: packaging in /home/moddo/.local/lib/python3.10/site-packages (from pytorch-ignite>=0.4.8->torch.optim) (24.1)\n",
            "Requirement already satisfied: filelock in /home/moddo/.local/lib/python3.10/site-packages (from torch>=1.10.0->torch.optim) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /home/moddo/.local/lib/python3.10/site-packages (from torch>=1.10.0->torch.optim) (4.12.2)\n",
            "Requirement already satisfied: networkx in /home/moddo/.local/lib/python3.10/site-packages (from torch>=1.10.0->torch.optim) (3.3)\n",
            "Requirement already satisfied: jinja2 in /home/moddo/.local/lib/python3.10/site-packages (from torch>=1.10.0->torch.optim) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /home/moddo/.local/lib/python3.10/site-packages (from torch>=1.10.0->torch.optim) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/moddo/.local/lib/python3.10/site-packages (from torch>=1.10.0->torch.optim) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/moddo/.local/lib/python3.10/site-packages (from torch>=1.10.0->torch.optim) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/moddo/.local/lib/python3.10/site-packages (from torch>=1.10.0->torch.optim) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/moddo/.local/lib/python3.10/site-packages (from torch>=1.10.0->torch.optim) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/moddo/.local/lib/python3.10/site-packages (from torch>=1.10.0->torch.optim) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/moddo/.local/lib/python3.10/site-packages (from torch>=1.10.0->torch.optim) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/moddo/.local/lib/python3.10/site-packages (from torch>=1.10.0->torch.optim) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/moddo/.local/lib/python3.10/site-packages (from torch>=1.10.0->torch.optim) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/moddo/.local/lib/python3.10/site-packages (from torch>=1.10.0->torch.optim) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/moddo/.local/lib/python3.10/site-packages (from torch>=1.10.0->torch.optim) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/moddo/.local/lib/python3.10/site-packages (from torch>=1.10.0->torch.optim) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/moddo/.local/lib/python3.10/site-packages (from torch>=1.10.0->torch.optim) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/moddo/.local/lib/python3.10/site-packages (from torch>=1.10.0->torch.optim) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /home/moddo/.local/lib/python3.10/site-packages (from torch>=1.10.0->torch.optim) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /home/moddo/.local/lib/python3.10/site-packages (from torch>=1.10.0->torch.optim) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/moddo/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.10.0->torch.optim) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/moddo/.local/lib/python3.10/site-packages (from torchvision>=0.11.1->torch.optim) (10.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/moddo/.local/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torch.optim) (2.1.5)\n",
            "\u001b[33mWARNING: Error parsing dependencies of distro-info: Invalid version: '1.1build1'\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch.utils.data (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for torch.utils.data\u001b[0m\u001b[31m\n",
            "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision.transforms (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for torchvision.transforms\u001b[0m\u001b[31m\n",
            "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement PIL (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for PIL\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#These are pip install commands, which will download all the libraries and tools you'll need for this project.\n",
        "#Once you've installed these, you shouldn't have to keep re-running this cell.\n",
        "!pip install kaggle\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install os\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install torch.optim\n",
        "!pip install torch.utils.data\n",
        "!pip install torchvision.transforms\n",
        "!pip install PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9a-FOXs4H9q",
        "outputId": "14b87b81-dd79-456d-f1a5-ce0f4287c61c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/moddo/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import time\n",
        "import copy\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import compute_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpckFvoh5wzx",
        "outputId": "f3304904-1c04-4380-e8e8-eed81143beec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/home/moddo/.local/bin/kaggle\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/home/moddo/.local/lib/python3.10/site-packages/kaggle/cli.py\", line 68, in main\n",
            "    out = args.func(**command_args)\n",
            "  File \"/home/moddo/.local/lib/python3.10/site-packages/kaggle/api/kaggle_api_extended.py\", line 1734, in dataset_download_cli\n",
            "    with self.build_kaggle_client() as kaggle:\n",
            "  File \"/home/moddo/.local/lib/python3.10/site-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n",
            "    username=self.config_values['username'],\n",
            "KeyError: 'username'\n",
            "unzip:  cannot find or open stanford-car-dataset-brands-only-csv-files.zip, stanford-car-dataset-brands-only-csv-files.zip.zip or stanford-car-dataset-brands-only-csv-files.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "#Set up your Kaggle account and add the JSON file into your Google Drive.\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/home/moddo/Kaggle/kaggle.json\"\n",
        "#We're downloading our modified brand dataset and unzipping it into our directory.\n",
        "!kaggle datasets download -d aditikashi/stanford-car-dataset-brands-only-csv-files\n",
        "!unzip stanford-car-dataset-brands-only-csv-files.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKA60UzvAfN0",
        "outputId": "60376d6f-e950-4686-ebc8-5aaab848ce7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Dataset:\n",
            "    imagename    label\n",
            "0  00001.jpg     Audi\n",
            "1  00002.jpg    Acura\n",
            "2  00003.jpg    Dodge\n",
            "3  00004.jpg  Hyundai\n",
            "4  00005.jpg     Ford\n",
            "Testing Dataset:\n",
            "    imagename    label\n",
            "0  00001.jpg   Suzuki\n",
            "1  00002.jpg  Ferrari\n",
            "2  00003.jpg     Jeep\n",
            "3  00004.jpg   Toyota\n",
            "4  00005.jpg    Tesla\n",
            "\n",
            "Car brand distribution in training dataset:\n",
            " label\n",
            "Chevrolet        905\n",
            "Dodge            630\n",
            "Audi             589\n",
            "BMW              531\n",
            "Ford             521\n",
            "Hyundai          438\n",
            "Mercedes-Benz    261\n",
            "Chrysler         260\n",
            "Acura            242\n",
            "GMC              238\n",
            "Bentley          238\n",
            "Jeep             220\n",
            "Nissan           171\n",
            "Toyota           168\n",
            "Suzuki           167\n",
            "Ferrari          164\n",
            "Honda            161\n",
            "Lamborghini      161\n",
            "Buick            158\n",
            "Aston            157\n",
            "Volkswagen       132\n",
            "Volvo            131\n",
            "Cadillac         129\n",
            "Rolls-Royce      114\n",
            "Spyker            88\n",
            "Land              86\n",
            "HUMMER            83\n",
            "Bugatti           77\n",
            "Infiniti          67\n",
            "FIAT              62\n",
            "Mitsubishi        48\n",
            "Jaguar            47\n",
            "Eagle             46\n",
            "Daewoo            45\n",
            "Geo               45\n",
            "AM                45\n",
            "McLaren           44\n",
            "Porsche           44\n",
            "Fisker            44\n",
            "Plymouth          44\n",
            "Scion             42\n",
            "Ram               41\n",
            "smart             40\n",
            "Isuzu             40\n",
            "Tesla             39\n",
            "Lincoln           39\n",
            "MINI              37\n",
            "Mazda             36\n",
            "Maybach           29\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Car brand distribution in testing dataset:\n",
            " label\n",
            "Chevrolet        894\n",
            "Dodge            623\n",
            "Audi             580\n",
            "BMW              524\n",
            "Ford             514\n",
            "Hyundai          433\n",
            "Mercedes-Benz    257\n",
            "Chrysler         256\n",
            "Acura            240\n",
            "GMC              235\n",
            "Bentley          234\n",
            "Jeep             218\n",
            "Nissan           170\n",
            "Suzuki           166\n",
            "Toyota           164\n",
            "Ferrari          162\n",
            "Honda            160\n",
            "Lamborghini      158\n",
            "Aston            157\n",
            "Buick            156\n",
            "Volkswagen       131\n",
            "Volvo            129\n",
            "Cadillac         128\n",
            "Rolls-Royce      112\n",
            "Spyker            87\n",
            "Land              84\n",
            "HUMMER            82\n",
            "Bugatti           75\n",
            "Infiniti          66\n",
            "FIAT              60\n",
            "Mitsubishi        47\n",
            "Jaguar            46\n",
            "Eagle             46\n",
            "Daewoo            45\n",
            "AM                44\n",
            "Plymouth          44\n",
            "McLaren           44\n",
            "Geo               44\n",
            "Fisker            43\n",
            "Porsche           43\n",
            "Scion             41\n",
            "Ram               41\n",
            "Isuzu             40\n",
            "smart             40\n",
            "Lincoln           39\n",
            "Tesla             38\n",
            "Mazda             36\n",
            "MINI              36\n",
            "Maybach           29\n",
            "Name: count, dtype: int64\n",
            "New Training Dataset shape: (5009, 2)\n",
            "New Testing Dataset shape: (4978, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_482572/2006875974.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  train_sampled_df = train_df.groupby('label').apply(lambda x: x.sample(min(len(x), 8000 // train_df['label'].nunique()))).reset_index(drop=True)\n",
            "/tmp/ipykernel_482572/2006875974.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  test_sampled_df = test_df.groupby('label').apply(lambda x: x.sample(min(len(x), 8000 // test_df['label'].nunique()))).reset_index(drop=True)\n"
          ]
        }
      ],
      "source": [
        "#This line specify the paths to the CSV file and the image folder. Do NOT edit this, since it matches the imported dataset.\n",
        "PATH = \"../cardata/\"\n",
        "\n",
        "#Create two pandas DataFrames that hold the info in the CSV files.\n",
        "train_df = pd.read_csv(f'{PATH}train.csv')\n",
        "test_df = pd.read_csv(f'{PATH}test.csv')\n",
        "\n",
        "# Let's inspect the data!\n",
        "print(\"Training Dataset:\\n\", train_df.head())\n",
        "print(\"Testing Dataset:\\n\", test_df.head())\n",
        "\n",
        "# Step 2: Check the distribution of car brands, a.k.a how many images of each brand there are.\n",
        "print(\"\\nCar brand distribution in training dataset:\\n\", train_df['label'].value_counts())\n",
        "print(\"\\nCar brand distribution in testing dataset:\\n\", test_df['label'].value_counts())\n",
        "\n",
        "# Step 3: Take a random sampling of data. The reason we do this is because Jupyter Notebook can't efficiently run all 8000 training and 8000 testing images, so we have to\n",
        "#have a smaller data set that can be run here. Don't worry about the semantics of this code, but all it's doing is taking 3000 sample images from each dataset. You can\n",
        "#change the number 3000 to a different number if you'd like to test it out. We do this process for both training and testing data.\n",
        "train_sampled_df = train_df.groupby('label').apply(lambda x: x.sample(min(len(x), 8000 // train_df['label'].nunique()))).reset_index(drop=True)\n",
        "test_sampled_df = test_df.groupby('label').apply(lambda x: x.sample(min(len(x), 8000 // test_df['label'].nunique()))).reset_index(drop=True)\n",
        "\n",
        "# Step 4: We can save these new datasets to new CSV files, new_train and new_test. The reason we made new files is in case we want to reaccess all of the data at any point.\n",
        "#For model development, you'll be using these new CSV files.\n",
        "train_sampled_df.to_csv('../cardata/new_train.csv', index=False)\n",
        "test_sampled_df.to_csv('../cardata/new_test.csv', index=False)\n",
        "\n",
        "#Let's inspect the size of the new datasets!\n",
        "print(\"New Training Dataset shape:\", train_sampled_df.shape)\n",
        "print(\"New Testing Dataset shape:\", test_sampled_df.shape)\n",
        "\n",
        "#TO-DO: Move your new_train and new_test files into the cardata folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "sWD8ThFGAk54",
        "outputId": "770f72cf-d963-41bb-a822-6e67ae52b0b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0/24\n",
            "Epoch: 1, Loss: 3.5025252521417705\n",
            "Training accuracy: 0.17408664524555206\n",
            "Epoch: 1, Loss: 3.4496078407688504\n",
            "Testing accuracy: 0.2752109467983246\n",
            "Testing AUROC (macro, OVR): 0.9102\n",
            "Epoch: 1/24\n",
            "Epoch: 2, Loss: 2.486154837972799\n",
            "Training accuracy: 0.4306248724460602\n",
            "Epoch: 2, Loss: 2.8380338071258207\n",
            "Testing accuracy: 0.4431498646736145\n",
            "Testing AUROC (macro, OVR): 0.9596\n",
            "Epoch: 2/24\n",
            "Epoch: 3, Loss: 1.9494526803873147\n",
            "Training accuracy: 0.6033140420913696\n"
          ]
        }
      ],
      "source": [
        "#Okay, now it's time to work on our model! We've given you some of the basic code and function structure you'll need.\n",
        "#This first section of code essentially reads, writes, and accesses our data. Don't worry about the functionality.\n",
        "class CustomCarDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        #The three values below this comment are important!!\n",
        "        self.labels_df = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        #Get a list of all the unique car brands for the classes.\n",
        "        self.classes = self.labels_df['label'].unique().tolist()\n",
        "        #Maps the labels to the indices.\n",
        "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            #Get the image file name and label from the dataframe.\n",
        "            img_name = os.path.join(self.img_dir, self.labels_df.iloc[idx, 0])\n",
        "            #Open the image and convert to RGB.\n",
        "            image = Image.open(img_name).convert('RGB')\n",
        "\n",
        "            #Get the corresponding label and map it to the index\n",
        "            label = self.class_to_idx[self.labels_df.iloc[idx, 1]]\n",
        "\n",
        "            #Apply the transformations you created.\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "\n",
        "            return image, label\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading index {idx}: {e}\")\n",
        "            return None  # or raise if you want to crash\n",
        "\n",
        "#This is where you'll add your image augmentation. Refer back to the image augmentation notebook for some guidance.\n",
        "#One function you'll definitely need is transforms.CenterCrop(). This is because the ResNet-50 model only uses images\n",
        "#with inputs of size 244 by 244 (hint!). Another function you'll need is transforms.ToTensor(), since Tensorflow will only process data\n",
        "#that is in tensor form. Finally, transforms.Normalize() is a way to standardize the images using ImageNet, which is typical\n",
        "#for any models that were pre-trained using ImageNet, like ResNet50! Essentially, ResNet was originally trained on the images\n",
        "#in ImageNet, so we adjust the range of our pixel values to match the range used in the ImageNet dataset.\n",
        "\n",
        "#We've given you some of the functions you'll need, so it's your job to go through documentation and test out some code.\n",
        "\n",
        "#DONE: Add the necessary functions we mentioned, and experiment with more image augmentation techniques that change more aspects of the images.\n",
        "#Again, refer back to the image augmentation notebook for this. Try to see what combinations can increase your accuracy.\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),  # randomly zooms in\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.3081, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "#These are file paths for the CSV and the image directories.\n",
        "train_img_dir = '../cardata/cars_train/'\n",
        "train_csv = '../cardata/new_train.csv'\n",
        "\n",
        "test_img_dir = '../cardata/cars_test/'\n",
        "test_csv = '../cardata/new_test.csv'\n",
        "\n",
        "#DONE: Create Dataset() instances here for the training and testing. Look at the def_init function at the very\n",
        "#beginning that we have provided for you. Think about how you could call this class (CustomCardataset()) and what input values\n",
        "#you might need to use. Hint: since this is a class, it won't be exactly like calling a function\n",
        "\n",
        "train_dataset = CustomCarDataset(img_dir=train_img_dir, csv_file=train_csv, transform=transform)\n",
        "test_dataset = CustomCarDataset(img_dir=test_img_dir, csv_file=test_csv, transform=transform)\n",
        "\n",
        "#DONE: Create DataLoader() instances here for the training and testing. Documentation is your friend! Search for\n",
        "#DataLoader documentation, and experiment with the parameters you give the function.\n",
        "\n",
        "\n",
        "\n",
        "#DONE: Prepare dataloaders and dataset sizes for the training and testing phases.\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "#DONE:Get the class names (car brands) and the number of car brands.\n",
        "all_brands = set(train_dataset.classes + test_dataset.classes)  # Merge train & test labels\n",
        "num_classes = len(all_brands)\n",
        "\n",
        "#TO-DO: Check if we can use torch.cuda for fast implementaiton or CPU.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "#Here's where you'll be implementing your model. Again, documentation, Google, and ChatGPT is your friend.\n",
        "#We'll leave in variable names so you have a general idea of what to follow and so that the code flows with the\n",
        "#pre-written aspects.\n",
        "if torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "elif torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_dataset.labels_df['label']),\n",
        "    y=train_dataset.labels_df['label']\n",
        ")\n",
        "\n",
        "# Map weights to index\n",
        "weight_tensor = torch.tensor([class_weights[train_dataset.class_to_idx[c]] for c in train_dataset.classes], dtype=torch.float).to(device)\n",
        "\n",
        "#DONE: Here is where you set the model to ResNet-50. Look at some of the parameters you might need.\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    if \"layer4\" in name or \"fc\" in name:\n",
        "        param.requires_grad = True\n",
        "\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(p=0.4),\n",
        "    nn.Linear(model.fc.in_features, num_classes)\n",
        ")\n",
        "\n",
        "#DONE: Here is where you will add some of the features of the model, like the loss function, optimizer, and learning\n",
        "#rate scheduler. You can use whatever features you'd like, and keep experimenting with different hyperparameters to\n",
        "#see what works best. Once again, look at documentation!\n",
        "criterion = nn.CrossEntropyLoss(weight=weight_tensor, label_smoothing=0.1)\n",
        "\n",
        "optimizer = torch.optim.SGD(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=0.01,\n",
        "    momentum=0.9,\n",
        "    weight_decay=5e-4\n",
        ")\n",
        "\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
        "\n",
        "# Modify the fully connected layer to match the number of car brands (hint: where did we get the number of car brands?).\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "#This section of the code creates the training and testing pipeline. While this is an important part of the computer vision\n",
        "#pipeline, it mainly involves iterating over data and finding accuracy, which are not as critical to your fundamental\n",
        "#understanding of computer vision as a whole. We've given you the code that will iterate through your model. Feel free to change\n",
        "#or add anything you'd like (hint: you can look into things like freezing a layer, adding a layer, etc).\n",
        "\n",
        "#TO-DO: Experiment as much as you'd like with adding layers, freezing layers, anything you'd like to try.\n",
        "def make_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "\n",
        "    since = time.time()\n",
        "\n",
        "    ##DONE: Save the best model and best accuracy.\n",
        "    \n",
        "    best_acc = 0.0\n",
        "    best_model = model.state_dict()\n",
        "    dataloaders = {'train': train_loader, 'test': test_loader}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        ##DONE: Print which epoch you are on.\n",
        "        \n",
        "        print(f'Epoch: {epoch}/{num_epochs - 1}')\n",
        "\n",
        "        if epoch == 5:\n",
        "            print(\"Unfreezing layer3 for fine-tuning\")\n",
        "            for name, param in model.named_parameters():\n",
        "                if \"layer3\" in name:\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            # Rebuild optimizer with new trainable params\n",
        "            optimizer = torch.optim.SGD(\n",
        "                filter(lambda p: p.requires_grad, model.parameters()),\n",
        "                lr=0.005,\n",
        "                momentum=0.9,\n",
        "                weight_decay=5e-4\n",
        "            )\n",
        "            scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
        "\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            runningLoss = 0.0       \n",
        "            runningCorrect = 0\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                # Zero the parameter gradients.\n",
        "                optimizer.zero_grad()\n",
        "                # This is a place where you could add more features, like cross-validation, freezing, etc.\n",
        "                \n",
        "                # Forward pass: run through the model forwards.\n",
        "                outputs = model(inputs)\n",
        "                # Backward pass + optimize: this only happens while in train mode.\n",
        "                loss = criterion(outputs,labels)\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                # Calculate running loss function and the number of correct guesses.\n",
        "                runningLoss += loss.item()\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                runningCorrect += torch.sum(labels.data == preds)\n",
        "            \n",
        "            # Calculate and print epoch loss, and continue training if it is the appropriate phase.\n",
        "            print(f'Epoch: {epoch+1}, Loss: {runningLoss/len(train_loader)}')\n",
        "            if phase == 'train':\n",
        "                epoch_acc = runningCorrect / len(train_dataset)\n",
        "                print(f\"Training accuracy: {epoch_acc}\")\n",
        "                scheduler.step(runningLoss/len(train_loader))\n",
        "                torch.save(model.state_dict(), 'car_brand_model.pth')\n",
        "            else:\n",
        "                epoch_acc = runningCorrect / len(test_dataset)\n",
        "                print(f\"Testing accuracy: {epoch_acc}\")\n",
        "                all_labels = []\n",
        "                all_probs = []\n",
        "            #This is just for auroc\n",
        "                with torch.no_grad():\n",
        "                    for inputs, labels in dataloaders[\"test\"]:\n",
        "                        inputs = inputs.to(device)\n",
        "                        labels = labels.to(device)\n",
        "                        outputs = model(inputs)\n",
        "                        probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "                        all_labels.extend(labels.cpu().numpy())\n",
        "                        all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "                try:\n",
        "                    epoch_auroc = roc_auc_score(all_labels, all_probs, multi_class='ovr')\n",
        "                    print(f\"Testing AUROC (macro, OVR): {epoch_auroc:.4f}\")\n",
        "                except ValueError as e:\n",
        "                    print(f\"Could not compute AUROC: {e}\")\n",
        "                \n",
        "        \n",
        "        if phase == 'test':\n",
        "            if epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_copy = copy.deepcopy(model.state_dict())\n",
        "                \n",
        "                        \n",
        "    # Check how much time training took.\n",
        "    time_elapsed = time.time() - since\n",
        "    # Load the best model weights for the next epoch.\n",
        "    model.load_state_dict(best_model_copy)\n",
        "    return model\n",
        "#TO-DO: Write this function that calls the training function with all its parameters.\n",
        "try:\n",
        "    modelf = make_model(model,criterion, optimizer,scheduler)\n",
        "    torch.save(modelf.state_dict(), 'car_brand_model.pth')\n",
        "except Exception as e:\n",
        "    print(f\"Error {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting anvil-uplink\n",
            "  Downloading anvil_uplink-0.5.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting argparse (from anvil-uplink)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: future in /home/moddo/.local/lib/python3.10/site-packages (from anvil-uplink) (0.18.3)\n",
            "Requirement already satisfied: six in /home/moddo/.local/lib/python3.10/site-packages (from anvil-uplink) (1.16.0)\n",
            "Collecting ws4py-sslupdate (from anvil-uplink)\n",
            "  Downloading ws4py_sslupdate-0.5.1b0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading anvil_uplink-0.5.2-py2.py3-none-any.whl (97 kB)\n",
            "Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Downloading ws4py_sslupdate-0.5.1b0-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[33mWARNING: Error parsing dependencies of distro-info: Invalid version: '1.1build1'\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: ws4py-sslupdate, argparse, anvil-uplink\n",
            "Successfully installed anvil-uplink-0.5.2 argparse-1.4.0 ws4py-sslupdate-0.5.1b0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install anvil-uplink"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import anvil.server\n",
        "\n",
        "anvil.server.connect(\"server_PQDMMEVWZGDVRMCVKNBP6S3I-7HCM3HYYXKK36MNM\")\n",
        "\n",
        "@anvil.server.callable\n",
        "def get_data(name):\n",
        "  print(f\"Hello from your own machine, {name}!\")\n",
        "  return [1, 2, 4, 8]\n",
        "\n",
        "anvil.server.wait_forever()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
